BISECT: running pass (1) Loop Vectorization on function (_Z3fooR1s)

LV: Checking a loop in "_Z3fooR1s" from example.ll:6:1
LV: Loop hints: force=? width=0 unroll=0
LV: Analyzing interleaved accesses...
LV: Creating an interleave group with:  store double %mul.1, double* %arrayidx.1, align 8, !dbg !49
LV: Inserted:  store double %mul, double* %arrayidx, align 16, !dbg !41
    into the interleave group with  store double %mul.1, double* %arrayidx.1, align 8, !dbg !49
LV: Creating an interleave group with:  %2 = load double, double* %arrayidx.1, align 8, !dbg !45
LV: Inserted:  %1 = load double, double* %arrayidx, align 16, !dbg !37
    into the interleave group with  %2 = load double, double* %arrayidx.1, align 8, !dbg !45
LV: Found trip count: 800
LV: The Smallest and Widest types: 64 / 64 bits.
LV: The Widest register safe to use is: 128 bits.
LV: Found uniform instruction:   %exitcond.1 = icmp eq i64 %indvars.iv.next, 1599, !dbg !51
LV: Found uniform instruction:   %arrayidx = getelementptr inbounds double, double* %0, i64 %indvars.iv, !dbg !36
LV: Found uniform instruction:   %arrayidx.1 = getelementptr inbounds double, double* %0, i64 %indvars.iv.next, !dbg !44
LV: Scalarizing:  tail call void @llvm.assume(i1 %maskcond), !dbg !35
LV: Scalarizing:  %arrayidx = getelementptr inbounds double, double* %0, i64 %indvars.iv, !dbg !36
LV: Scalarizing:  %1 = load double, double* %arrayidx, align 16, !dbg !37
LV: Scalarizing:  %add = fadd double %1, 1.000000e+00, !dbg !38
LV: Scalarizing:  tail call void @llvm.assume(i1 %maskcond), !dbg !39
LV: Scalarizing:  %mul = fmul double %add, 2.000000e+00, !dbg !40
LV: Scalarizing:  store double %mul, double* %arrayidx, align 16, !dbg !41
LV: Scalarizing:  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1, !dbg !42
LV: Scalarizing:  tail call void @llvm.assume(i1 %maskcond), !dbg !43
LV: Scalarizing:  %arrayidx.1 = getelementptr inbounds double, double* %0, i64 %indvars.iv.next, !dbg !44
LV: Scalarizing:  %2 = load double, double* %arrayidx.1, align 8, !dbg !45
LV: Scalarizing:  %add.1 = fadd double %2, 1.000000e+00, !dbg !46
LV: Scalarizing:  tail call void @llvm.assume(i1 %maskcond), !dbg !47
LV: Scalarizing:  %mul.1 = fmul double %add.1, 2.000000e+00, !dbg !48
LV: Scalarizing:  store double %mul.1, double* %arrayidx.1, align 8, !dbg !49
LV: Scalarizing:  tail call void @llvm.assume(i1 %maskcond), !dbg !35
LV: Scalarizing:  %arrayidx = getelementptr inbounds double, double* %0, i64 %indvars.iv, !dbg !36
LV: Scalarizing:  tail call void @llvm.assume(i1 %maskcond), !dbg !39
LV: Scalarizing:  tail call void @llvm.assume(i1 %maskcond), !dbg !43
LV: Scalarizing:  %arrayidx.1 = getelementptr inbounds double, double* %0, i64 %indvars.iv.next, !dbg !44
LV: Scalarizing:  tail call void @llvm.assume(i1 %maskcond), !dbg !47
digraph VPlan {
graph [labelloc=t, fontsize=30; label="Vectorization Plan\nInitial VPlan for VF=\{1\},UF\>=1"]
node [shape=rect, fontname=Courier, fontsize=30]
edge [fontname=Courier, fontsize=30]
compound=true
  N0 [label =
    "for.body:\n" +
      "WIDEN-INDUCTION %indvars.iv = phi 0, %indvars.iv.next.1\l" +
      "CLONE call %maskcond, @llvm.assume\l" +
      "CLONE %arrayidx = getelementptr %0, %indvars.iv\l" +
      "CLONE %1 = load %arrayidx\l" +
      "CLONE %add = fadd %1, 1.000000e+00\l" +
      "CLONE call %maskcond, @llvm.assume\l" +
      "CLONE %mul = fmul %add, 2.000000e+00\l" +
      "CLONE store %mul, %arrayidx\l" +
      "CLONE %indvars.iv.next = add %indvars.iv, 1\l" +
      "CLONE call %maskcond, @llvm.assume\l" +
      "CLONE %arrayidx.1 = getelementptr %0, %indvars.iv.next\l" +
      "CLONE %2 = load %arrayidx.1\l" +
      "CLONE %add.1 = fadd %2, 1.000000e+00\l" +
      "CLONE call %maskcond, @llvm.assume\l" +
      "CLONE %mul.1 = fmul %add.1, 2.000000e+00\l" +
      "CLONE store %mul.1, %arrayidx.1\l"
  ]
}
digraph VPlan {
graph [labelloc=t, fontsize=30; label="Vectorization Plan\nInitial VPlan for VF=\{2\},UF\>=1"]
node [shape=rect, fontname=Courier, fontsize=30]
edge [fontname=Courier, fontsize=30]
compound=true
  N0 [label =
    "for.body:\n" +
      "WIDEN-INDUCTION %indvars.iv = phi 0, %indvars.iv.next.1\l" +
      "REPLICATE call %maskcond, @llvm.assume\l" +
      "CLONE %arrayidx = getelementptr %0, %indvars.iv\l" +
      "INTERLEAVE-GROUP with factor 2 at %1\l" +
      "  %1 = load %arrayidx 0\l" +
      "  %2 = load %arrayidx.1 1\l" +
      "WIDEN\l" +
      "  %add = fadd %1, 1.000000e+00\l" +
      "REPLICATE call %maskcond, @llvm.assume\l" +
      "WIDEN\l" +
      "  %mul = fmul %add, 2.000000e+00\l" +
      "WIDEN\l" +
      "  %indvars.iv.next = add %indvars.iv, 1\l" +
      "REPLICATE call %maskcond, @llvm.assume\l" +
      "CLONE %arrayidx.1 = getelementptr %0, %indvars.iv.next\l" +
      "WIDEN\l" +
      "  %add.1 = fadd %2, 1.000000e+00\l" +
      "REPLICATE call %maskcond, @llvm.assume\l" +
      "WIDEN\l" +
      "  %mul.1 = fmul %add.1, 2.000000e+00\l" +
      "INTERLEAVE-GROUP with factor 2 at <badref>\l" +
      "  store %mul, %arrayidx 0\l" +
      "  store %mul.1, %arrayidx.1 1\l"
  ]
}
LV: Found an estimated cost of 0 for VF 1 For instruction:   %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next.1, %for.body ], !dbg !34
LV: Found an estimated cost of 0 for VF 1 For instruction:   %arrayidx = getelementptr inbounds double, double* %0, i64 %indvars.iv, !dbg !36
LV: Found an estimated cost of 1 for VF 1 For instruction:   %1 = load double, double* %arrayidx, align 16, !dbg !37
LV: Found an estimated cost of 2 for VF 1 For instruction:   %add = fadd double %1, 1.000000e+00, !dbg !38
LV: Found an estimated cost of 2 for VF 1 For instruction:   %mul = fmul double %add, 2.000000e+00, !dbg !40
LV: Found an estimated cost of 1 for VF 1 For instruction:   store double %mul, double* %arrayidx, align 16, !dbg !41
LV: Found an estimated cost of 1 for VF 1 For instruction:   %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1, !dbg !42
LV: Found an estimated cost of 0 for VF 1 For instruction:   %arrayidx.1 = getelementptr inbounds double, double* %0, i64 %indvars.iv.next, !dbg !44
LV: Found an estimated cost of 1 for VF 1 For instruction:   %2 = load double, double* %arrayidx.1, align 8, !dbg !45
LV: Found an estimated cost of 2 for VF 1 For instruction:   %add.1 = fadd double %2, 1.000000e+00, !dbg !46
LV: Found an estimated cost of 2 for VF 1 For instruction:   %mul.1 = fmul double %add.1, 2.000000e+00, !dbg !48
LV: Found an estimated cost of 1 for VF 1 For instruction:   store double %mul.1, double* %arrayidx.1, align 8, !dbg !49
LV: Found an estimated cost of 1 for VF 1 For instruction:   %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.next, 1, !dbg !50
LV: Found an estimated cost of 1 for VF 1 For instruction:   %exitcond.1 = icmp eq i64 %indvars.iv.next, 1599, !dbg !51
LV: Found an estimated cost of 0 for VF 1 For instruction:   br i1 %exitcond.1, label %for.end, label %for.body, !dbg !52
LV: Scalar loop costs: 15.
LV: Found an estimated cost of 0 for VF 2 For instruction:   %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next.1, %for.body ], !dbg !34
LV: Found an estimated cost of 0 for VF 2 For instruction:   %arrayidx = getelementptr inbounds double, double* %0, i64 %indvars.iv, !dbg !36
LV: Found an estimated cost of 6 for VF 2 For instruction:   %1 = load double, double* %arrayidx, align 16, !dbg !37
LV: Found an estimated cost of 2 for VF 2 For instruction:   %add = fadd double %1, 1.000000e+00, !dbg !38
LV: Found an estimated cost of 2 for VF 2 For instruction:   %mul = fmul double %add, 2.000000e+00, !dbg !40
LV: Found an estimated cost of 0 for VF 2 For instruction:   store double %mul, double* %arrayidx, align 16, !dbg !41
LV: Found an estimated cost of 1 for VF 2 For instruction:   %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1, !dbg !42
LV: Found an estimated cost of 0 for VF 2 For instruction:   %arrayidx.1 = getelementptr inbounds double, double* %0, i64 %indvars.iv.next, !dbg !44
LV: Found an estimated cost of 0 for VF 2 For instruction:   %2 = load double, double* %arrayidx.1, align 8, !dbg !45
LV: Found an estimated cost of 2 for VF 2 For instruction:   %add.1 = fadd double %2, 1.000000e+00, !dbg !46
LV: Found an estimated cost of 2 for VF 2 For instruction:   %mul.1 = fmul double %add.1, 2.000000e+00, !dbg !48
LV: Found an estimated cost of 6 for VF 2 For instruction:   store double %mul.1, double* %arrayidx.1, align 8, !dbg !49
LV: Found an estimated cost of 1 for VF 2 For instruction:   %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.next, 1, !dbg !50
LV: Found an estimated cost of 1 for VF 2 For instruction:   %exitcond.1 = icmp eq i64 %indvars.iv.next, 1599, !dbg !51
LV: Found an estimated cost of 0 for VF 2 For instruction:   br i1 %exitcond.1, label %for.end, label %for.body, !dbg !52
LV: Vector loop of width 2 costs: 11.
LV: Selecting VF: 2.
LV: The target has 16 registers
LV(REG): Calculating max register usage:
LV(REG): At #0 Interval # 0
LV(REG): At #2 Interval # 1
LV(REG): At #3 Interval # 2
LV(REG): At #4 Interval # 3
LV(REG): At #6 Interval # 3
LV(REG): At #8 Interval # 1
LV(REG): At #10 Interval # 1
LV(REG): At #11 Interval # 2
LV(REG): At #12 Interval # 3
LV(REG): At #14 Interval # 3
LV(REG): At #16 Interval # 1
LV(REG): At #17 Interval # 2
LV(REG): VF = 2
LV(REG): Found max usage: 2
LV(REG): Found invariant usage: 2
LV: Loop cost is 23
LV: Not Interleaving.
LV: Interleaving is not beneficial.
LV: Found a vectorizable loop (2) in example.ll:6:1
Setting best plan to VF=2, UF=1
chrisDebugify: F:
; Function Attrs: nounwind uwtable
define void @_Z3fooR1s(%struct.s* nocapture readonly dereferenceable(8) %x) #0 !dbg !6 {
entry:
  %a = getelementptr inbounds %struct.s, %struct.s* %x, i64 0, i32 0, !dbg !28
  call void @llvm.dbg.value(metadata double** %a, metadata !9, metadata !DIExpression()), !dbg !28
  %0 = load double*, double** %a, align 8, !dbg !29
  %ptrint = ptrtoint double* %0 to i64
  call void @llvm.dbg.value(metadata double* %0, metadata !11, metadata !DIExpression()), !dbg !29
  %1 = ptrtoint double* %0 to i64, !dbg !30
  call void @llvm.dbg.value(metadata i64 %ptrint, metadata !12, metadata !DIExpression()), !dbg !30
  %maskedptr = and i64 %ptrint, 31, !dbg !31
  call void @llvm.dbg.value(metadata i64 %maskedptr, metadata !13, metadata !DIExpression()), !dbg !31
  %maskcond = icmp eq i64 %maskedptr, 0, !dbg !32
  call void @llvm.dbg.value(metadata i1 %maskcond, metadata !14, metadata !DIExpression()), !dbg !32
  br i1 false, label %scalar.ph, label %vector.scevcheck, !dbg !33

vector.scevcheck:                                 ; preds = %entry
  %scevgep = getelementptr double, double* %0, i64 1, !dbg !33
  %scevgep1 = ptrtoint double* %scevgep to i64
  %mul2 = call { i64, i1 } @llvm.umul.with.overflow.i64(i64 16, i64 799), !dbg !33
  %mul.result = extractvalue { i64, i1 } %mul2, 0, !dbg !33
  %mul.overflow = extractvalue { i64, i1 } %mul2, 1, !dbg !33
  %2 = add i64 %scevgep1, %mul.result, !dbg !33
  %3 = sub i64 %scevgep1, %mul.result, !dbg !33
  %4 = icmp ugt i64 %3, %scevgep1, !dbg !33
  %5 = icmp ult i64 %2, %scevgep1, !dbg !33
  %6 = select i1 false, i1 %4, i1 %5, !dbg !33
  %7 = or i1 %6, %mul.overflow, !dbg !33
  %8 = or i1 false, %7, !dbg !33
  %mul3 = call { i64, i1 } @llvm.umul.with.overflow.i64(i64 16, i64 799), !dbg !33
  %mul.result4 = extractvalue { i64, i1 } %mul3, 0, !dbg !33
  %mul.overflow5 = extractvalue { i64, i1 } %mul3, 1, !dbg !33
  %9 = add i64 %ptrint, %mul.result4, !dbg !33
  %10 = sub i64 %ptrint, %mul.result4, !dbg !33
  %11 = icmp ugt i64 %10, %ptrint, !dbg !33
  %12 = icmp ult i64 %9, %ptrint, !dbg !33
  %13 = select i1 false, i1 %11, i1 %12, !dbg !33
  %14 = or i1 %13, %mul.overflow5, !dbg !33
  %15 = or i1 %8, %14, !dbg !33
  br i1 %15, label %scalar.ph, label %vector.ph, !dbg !33

vector.ph:                                        ; preds = %vector.scevcheck
  br label %vector.body, !dbg !33

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %vec.ind = phi <2 x i64> [ <i64 0, i64 2>, %vector.ph ], [ %vec.ind.next, %vector.body ], !dbg !34
  %offset.idx = mul i64 %index, 2
  %16 = add i64 %offset.idx, 0
  %17 = add i64 %offset.idx, 2
  tail call void @llvm.assume(i1 %maskcond), !dbg !35
  tail call void @llvm.assume(i1 %maskcond), !dbg !35
  %18 = getelementptr inbounds double, double* %0, i64 %16, !dbg !36
  %19 = getelementptr inbounds double, double* %18, i32 0, !dbg !36
  %20 = bitcast double* %19 to <4 x double>*, !dbg !36
  %wide.vec = load <4 x double>, <4 x double>* %20, align 8, !dbg !37
  %strided.vec = shufflevector <4 x double> %wide.vec, <4 x double> undef, <2 x i32> <i32 0, i32 2>, !dbg !37
  %strided.vec6 = shufflevector <4 x double> %wide.vec, <4 x double> undef, <2 x i32> <i32 1, i32 3>, !dbg !37
  %21 = fadd <2 x double> %strided.vec, <double 1.000000e+00, double 1.000000e+00>, !dbg !38
  tail call void @llvm.assume(i1 %maskcond), !dbg !39
  tail call void @llvm.assume(i1 %maskcond), !dbg !39
  %22 = fmul <2 x double> %21, <double 2.000000e+00, double 2.000000e+00>, !dbg !40
  %23 = add nuw nsw <2 x i64> %vec.ind, <i64 1, i64 1>, !dbg !41
  tail call void @llvm.assume(i1 %maskcond), !dbg !42
  tail call void @llvm.assume(i1 %maskcond), !dbg !42
  %24 = extractelement <2 x i64> %23, i32 0, !dbg !43
  %25 = getelementptr inbounds double, double* %0, i64 %24, !dbg !43
  %26 = fadd <2 x double> %strided.vec6, <double 1.000000e+00, double 1.000000e+00>, !dbg !44
  tail call void @llvm.assume(i1 %maskcond), !dbg !45
  tail call void @llvm.assume(i1 %maskcond), !dbg !45
  %27 = fmul <2 x double> %26, <double 2.000000e+00, double 2.000000e+00>, !dbg !46
  %28 = getelementptr inbounds double, double* %25, i32 -1, !dbg !43
  %29 = bitcast double* %28 to <4 x double>*, !dbg !43
  %30 = shufflevector <2 x double> %22, <2 x double> %27, <4 x i32> <i32 0, i32 1, i32 2, i32 3>, !dbg !47
  %interleaved.vec = shufflevector <4 x double> %30, <4 x double> undef, <4 x i32> <i32 0, i32 2, i32 1, i32 3>, !dbg !47
  store <4 x double> %interleaved.vec, <4 x double>* %29, align 8, !dbg !47
  %index.next = add i64 %index, 2
  %vec.ind.next = add <2 x i64> %vec.ind, <i64 4, i64 4>, !dbg !34
  %31 = icmp eq i64 %index.next, 800
  br i1 %31, label %middle.block, label %vector.body, !llvm.loop !48

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 800, 800, !dbg !50
  br i1 %cmp.n, label %for.end, label %scalar.ph, !dbg !50

scalar.ph:                                        ; preds = %middle.block, %vector.scevcheck, %entry
  %bc.resume.val = phi i64 [ 1600, %middle.block ], [ 0, %entry ], [ 0, %vector.scevcheck ], !dbg !34
  br label %for.body, !dbg !33

for.body:                                         ; preds = %for.body, %scalar.ph
  %indvars.iv = phi i64 [ %bc.resume.val, %scalar.ph ], [ %indvars.iv.next.1, %for.body ], !dbg !34
  call void @llvm.dbg.value(metadata i64 %indvars.iv, metadata !16, metadata !DIExpression()), !dbg !34
  tail call void @llvm.assume(i1 %maskcond), !dbg !35
  %arrayidx = getelementptr inbounds double, double* %0, i64 %indvars.iv, !dbg !36
  call void @llvm.dbg.value(metadata double* %arrayidx, metadata !17, metadata !DIExpression()), !dbg !36
  %32 = load double, double* %arrayidx, align 16, !dbg !37
  call void @llvm.dbg.value(metadata double %32, metadata !18, metadata !DIExpression()), !dbg !37
  %add = fadd double %32, 1.000000e+00, !dbg !38
  call void @llvm.dbg.value(metadata double %add, metadata !19, metadata !DIExpression()), !dbg !38
  tail call void @llvm.assume(i1 %maskcond), !dbg !39
  %mul = fmul double %add, 2.000000e+00, !dbg !40
  call void @llvm.dbg.value(metadata double %mul, metadata !20, metadata !DIExpression()), !dbg !40
  store double %mul, double* %arrayidx, align 16, !dbg !51
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1, !dbg !41
  call void @llvm.dbg.value(metadata i64 %indvars.iv.next, metadata !21, metadata !DIExpression()), !dbg !41
  tail call void @llvm.assume(i1 %maskcond), !dbg !42
  %arrayidx.1 = getelementptr inbounds double, double* %0, i64 %indvars.iv.next, !dbg !43
  call void @llvm.dbg.value(metadata double* %arrayidx.1, metadata !22, metadata !DIExpression()), !dbg !43
  %33 = load double, double* %arrayidx.1, align 8, !dbg !52
  call void @llvm.dbg.value(metadata double %33, metadata !23, metadata !DIExpression()), !dbg !52
  %add.1 = fadd double %33, 1.000000e+00, !dbg !44
  call void @llvm.dbg.value(metadata double %add.1, metadata !24, metadata !DIExpression()), !dbg !44
  tail call void @llvm.assume(i1 %maskcond), !dbg !45
  %mul.1 = fmul double %add.1, 2.000000e+00, !dbg !46
  call void @llvm.dbg.value(metadata double %mul.1, metadata !25, metadata !DIExpression()), !dbg !46
  store double %mul.1, double* %arrayidx.1, align 8, !dbg !47
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.next, 1, !dbg !53
  call void @llvm.dbg.value(metadata i64 %indvars.iv.next.1, metadata !26, metadata !DIExpression()), !dbg !53
  %exitcond.1 = icmp eq i64 %indvars.iv.next, 1599, !dbg !54
  call void @llvm.dbg.value(metadata i1 %exitcond.1, metadata !27, metadata !DIExpression()), !dbg !54
  br i1 %exitcond.1, label %for.end, label %for.body, !dbg !50, !llvm.loop !55

for.end:                                          ; preds = %middle.block, %for.body
  ret void, !dbg !56
}

ERROR: Instruction with empty DebugLoc in function _Z3fooR1s --  %ptrint = ptrtoint double* %0 to i64
ERROR: Instruction with empty DebugLoc in function _Z3fooR1s --  %scevgep1 = ptrtoint double* %scevgep to i64
ERROR: Instruction with empty DebugLoc in function _Z3fooR1s --  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
ERROR: Instruction with empty DebugLoc in function _Z3fooR1s --  %offset.idx = mul i64 %index, 2
ERROR: Instruction with empty DebugLoc in function _Z3fooR1s --  %16 = add i64 %offset.idx, 0
ERROR: Instruction with empty DebugLoc in function _Z3fooR1s --  %17 = add i64 %offset.idx, 2
ERROR: Instruction with empty DebugLoc in function _Z3fooR1s --  %index.next = add i64 %index, 2
ERROR: Instruction with empty DebugLoc in function _Z3fooR1s --  %31 = icmp eq i64 %index.next, 800
ERROR: Instruction with empty DebugLoc in function _Z3fooR1s --  br i1 %31, label %middle.block, label %vector.body, !llvm.loop !48
CheckFunctionDebugify [Loop Vectorization]: FAIL
chrisDebugify: F:
; Function Attrs: nounwind uwtable
define void @_Z3fooR1s(%struct.s* nocapture readonly dereferenceable(8) %x) #0 !dbg !6 {
entry:
  %a = getelementptr inbounds %struct.s, %struct.s* %x, i64 0, i32 0, !dbg !80
  call void @llvm.dbg.value(metadata double** %a, metadata !9, metadata !DIExpression()), !dbg !80
  %0 = load double*, double** %a, align 8, !dbg !81
  call void @llvm.dbg.value(metadata double* %0, metadata !11, metadata !DIExpression()), !dbg !81
  %ptrint = ptrtoint double* %0 to i64, !dbg !82
  call void @llvm.dbg.value(metadata i64 %ptrint, metadata !12, metadata !DIExpression()), !dbg !82
  %1 = ptrtoint double* %0 to i64, !dbg !83
  call void @llvm.dbg.value(metadata i64 %1, metadata !13, metadata !DIExpression()), !dbg !83
  %maskedptr = and i64 %ptrint, 31, !dbg !84
  call void @llvm.dbg.value(metadata i64 %maskedptr, metadata !14, metadata !DIExpression()), !dbg !84
  %maskcond = icmp eq i64 %maskedptr, 0, !dbg !85
  call void @llvm.dbg.value(metadata i1 %maskcond, metadata !15, metadata !DIExpression()), !dbg !85
  br i1 false, label %scalar.ph, label %vector.scevcheck, !dbg !86

vector.scevcheck:                                 ; preds = %entry
  %scevgep = getelementptr double, double* %0, i64 1, !dbg !87
  call void @llvm.dbg.value(metadata double* %scevgep, metadata !17, metadata !DIExpression()), !dbg !87
  %scevgep1 = ptrtoint double* %scevgep to i64, !dbg !88
  call void @llvm.dbg.value(metadata i64 %scevgep1, metadata !18, metadata !DIExpression()), !dbg !88
  %mul2 = call { i64, i1 } @llvm.umul.with.overflow.i64(i64 16, i64 799), !dbg !89
  call void @llvm.dbg.value(metadata { i64, i1 } %mul2, metadata !19, metadata !DIExpression()), !dbg !89
  %mul.result = extractvalue { i64, i1 } %mul2, 0, !dbg !90
  call void @llvm.dbg.value(metadata i64 %mul.result, metadata !21, metadata !DIExpression()), !dbg !90
  %mul.overflow = extractvalue { i64, i1 } %mul2, 1, !dbg !91
  call void @llvm.dbg.value(metadata i1 %mul.overflow, metadata !22, metadata !DIExpression()), !dbg !91
  %2 = add i64 %scevgep1, %mul.result, !dbg !92
  call void @llvm.dbg.value(metadata i64 %2, metadata !23, metadata !DIExpression()), !dbg !92
  %3 = sub i64 %scevgep1, %mul.result, !dbg !93
  call void @llvm.dbg.value(metadata i64 %3, metadata !24, metadata !DIExpression()), !dbg !93
  %4 = icmp ugt i64 %3, %scevgep1, !dbg !94
  call void @llvm.dbg.value(metadata i1 %4, metadata !25, metadata !DIExpression()), !dbg !94
  %5 = icmp ult i64 %2, %scevgep1, !dbg !95
  call void @llvm.dbg.value(metadata i1 %5, metadata !26, metadata !DIExpression()), !dbg !95
  %6 = select i1 false, i1 %4, i1 %5, !dbg !96
  call void @llvm.dbg.value(metadata i1 %6, metadata !27, metadata !DIExpression()), !dbg !96
  %7 = or i1 %6, %mul.overflow, !dbg !97
  call void @llvm.dbg.value(metadata i1 %7, metadata !28, metadata !DIExpression()), !dbg !97
  %8 = or i1 false, %7, !dbg !98
  call void @llvm.dbg.value(metadata i1 %8, metadata !29, metadata !DIExpression()), !dbg !98
  %mul3 = call { i64, i1 } @llvm.umul.with.overflow.i64(i64 16, i64 799), !dbg !99
  call void @llvm.dbg.value(metadata { i64, i1 } %mul3, metadata !30, metadata !DIExpression()), !dbg !99
  %mul.result4 = extractvalue { i64, i1 } %mul3, 0, !dbg !100
  call void @llvm.dbg.value(metadata i64 %mul.result4, metadata !31, metadata !DIExpression()), !dbg !100
  %mul.overflow5 = extractvalue { i64, i1 } %mul3, 1, !dbg !101
  call void @llvm.dbg.value(metadata i1 %mul.overflow5, metadata !32, metadata !DIExpression()), !dbg !101
  %9 = add i64 %ptrint, %mul.result4, !dbg !102
  call void @llvm.dbg.value(metadata i64 %9, metadata !33, metadata !DIExpression()), !dbg !102
  %10 = sub i64 %ptrint, %mul.result4, !dbg !103
  call void @llvm.dbg.value(metadata i64 %10, metadata !34, metadata !DIExpression()), !dbg !103
  %11 = icmp ugt i64 %10, %ptrint, !dbg !104
  call void @llvm.dbg.value(metadata i1 %11, metadata !35, metadata !DIExpression()), !dbg !104
  %12 = icmp ult i64 %9, %ptrint, !dbg !105
  call void @llvm.dbg.value(metadata i1 %12, metadata !36, metadata !DIExpression()), !dbg !105
  %13 = select i1 false, i1 %11, i1 %12, !dbg !106
  call void @llvm.dbg.value(metadata i1 %13, metadata !37, metadata !DIExpression()), !dbg !106
  %14 = or i1 %13, %mul.overflow5, !dbg !107
  call void @llvm.dbg.value(metadata i1 %14, metadata !38, metadata !DIExpression()), !dbg !107
  %15 = or i1 %8, %14, !dbg !108
  call void @llvm.dbg.value(metadata i1 %15, metadata !39, metadata !DIExpression()), !dbg !108
  br i1 %15, label %scalar.ph, label %vector.ph, !dbg !109

vector.ph:                                        ; preds = %vector.scevcheck
  br label %vector.body, !dbg !110

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ], !dbg !111
  %vec.ind = phi <2 x i64> [ <i64 0, i64 2>, %vector.ph ], [ %vec.ind.next, %vector.body ], !dbg !112
  call void @llvm.dbg.value(metadata i64 %index, metadata !40, metadata !DIExpression()), !dbg !111
  call void @llvm.dbg.value(metadata <2 x i64> %vec.ind, metadata !41, metadata !DIExpression()), !dbg !112
  %offset.idx = mul i64 %index, 2, !dbg !113
  call void @llvm.dbg.value(metadata i64 %offset.idx, metadata !42, metadata !DIExpression()), !dbg !113
  %16 = add i64 %offset.idx, 0, !dbg !114
  call void @llvm.dbg.value(metadata i64 %16, metadata !43, metadata !DIExpression()), !dbg !114
  %17 = add i64 %offset.idx, 2, !dbg !115
  call void @llvm.dbg.value(metadata i64 %17, metadata !44, metadata !DIExpression()), !dbg !115
  tail call void @llvm.assume(i1 %maskcond), !dbg !116
  tail call void @llvm.assume(i1 %maskcond), !dbg !117
  %18 = getelementptr inbounds double, double* %0, i64 %16, !dbg !118
  call void @llvm.dbg.value(metadata double* %18, metadata !45, metadata !DIExpression()), !dbg !118
  %19 = getelementptr inbounds double, double* %18, i32 0, !dbg !119
  call void @llvm.dbg.value(metadata double* %19, metadata !46, metadata !DIExpression()), !dbg !119
  %20 = bitcast double* %19 to <4 x double>*, !dbg !120
  call void @llvm.dbg.value(metadata <4 x double>* %20, metadata !47, metadata !DIExpression()), !dbg !120
  %wide.vec = load <4 x double>, <4 x double>* %20, align 8, !dbg !121
  call void @llvm.dbg.value(metadata <4 x double> %wide.vec, metadata !48, metadata !DIExpression()), !dbg !121
  %strided.vec = shufflevector <4 x double> %wide.vec, <4 x double> undef, <2 x i32> <i32 0, i32 2>, !dbg !122
  call void @llvm.dbg.value(metadata <2 x double> %strided.vec, metadata !50, metadata !DIExpression()), !dbg !122
  %strided.vec6 = shufflevector <4 x double> %wide.vec, <4 x double> undef, <2 x i32> <i32 1, i32 3>, !dbg !123
  call void @llvm.dbg.value(metadata <2 x double> %strided.vec6, metadata !51, metadata !DIExpression()), !dbg !123
  %21 = fadd <2 x double> %strided.vec, <double 1.000000e+00, double 1.000000e+00>, !dbg !124
  call void @llvm.dbg.value(metadata <2 x double> %21, metadata !52, metadata !DIExpression()), !dbg !124
  tail call void @llvm.assume(i1 %maskcond), !dbg !125
  tail call void @llvm.assume(i1 %maskcond), !dbg !126
  %22 = fmul <2 x double> %21, <double 2.000000e+00, double 2.000000e+00>, !dbg !127
  call void @llvm.dbg.value(metadata <2 x double> %22, metadata !53, metadata !DIExpression()), !dbg !127
  %23 = add nuw nsw <2 x i64> %vec.ind, <i64 1, i64 1>, !dbg !128
  call void @llvm.dbg.value(metadata <2 x i64> %23, metadata !54, metadata !DIExpression()), !dbg !128
  tail call void @llvm.assume(i1 %maskcond), !dbg !129
  tail call void @llvm.assume(i1 %maskcond), !dbg !130
  %24 = extractelement <2 x i64> %23, i32 0, !dbg !131
  call void @llvm.dbg.value(metadata i64 %24, metadata !55, metadata !DIExpression()), !dbg !131
  %25 = getelementptr inbounds double, double* %0, i64 %24, !dbg !132
  call void @llvm.dbg.value(metadata double* %25, metadata !56, metadata !DIExpression()), !dbg !132
  %26 = fadd <2 x double> %strided.vec6, <double 1.000000e+00, double 1.000000e+00>, !dbg !133
  call void @llvm.dbg.value(metadata <2 x double> %26, metadata !57, metadata !DIExpression()), !dbg !133
  tail call void @llvm.assume(i1 %maskcond), !dbg !134
  tail call void @llvm.assume(i1 %maskcond), !dbg !135
  %27 = fmul <2 x double> %26, <double 2.000000e+00, double 2.000000e+00>, !dbg !136
  call void @llvm.dbg.value(metadata <2 x double> %27, metadata !58, metadata !DIExpression()), !dbg !136
  %28 = getelementptr inbounds double, double* %25, i32 -1, !dbg !137
  call void @llvm.dbg.value(metadata double* %28, metadata !59, metadata !DIExpression()), !dbg !137
  %29 = bitcast double* %28 to <4 x double>*, !dbg !138
  call void @llvm.dbg.value(metadata <4 x double>* %29, metadata !60, metadata !DIExpression()), !dbg !138
  %30 = shufflevector <2 x double> %22, <2 x double> %27, <4 x i32> <i32 0, i32 1, i32 2, i32 3>, !dbg !139
  call void @llvm.dbg.value(metadata <4 x double> %30, metadata !61, metadata !DIExpression()), !dbg !139
  %interleaved.vec = shufflevector <4 x double> %30, <4 x double> undef, <4 x i32> <i32 0, i32 2, i32 1, i32 3>, !dbg !140
  call void @llvm.dbg.value(metadata <4 x double> %interleaved.vec, metadata !62, metadata !DIExpression()), !dbg !140
  store <4 x double> %interleaved.vec, <4 x double>* %29, align 8, !dbg !141
  %index.next = add i64 %index, 2, !dbg !142
  call void @llvm.dbg.value(metadata i64 %index.next, metadata !63, metadata !DIExpression()), !dbg !142
  %vec.ind.next = add <2 x i64> %vec.ind, <i64 4, i64 4>, !dbg !143
  call void @llvm.dbg.value(metadata <2 x i64> %vec.ind.next, metadata !64, metadata !DIExpression()), !dbg !143
  %31 = icmp eq i64 %index.next, 800, !dbg !144
  call void @llvm.dbg.value(metadata i1 %31, metadata !65, metadata !DIExpression()), !dbg !144
  br i1 %31, label %middle.block, label %vector.body, !dbg !145, !llvm.loop !146

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 800, 800, !dbg !148
  call void @llvm.dbg.value(metadata i1 %cmp.n, metadata !66, metadata !DIExpression()), !dbg !148
  br i1 %cmp.n, label %for.end, label %scalar.ph, !dbg !149

scalar.ph:                                        ; preds = %middle.block, %vector.scevcheck, %entry
  %bc.resume.val = phi i64 [ 1600, %middle.block ], [ 0, %entry ], [ 0, %vector.scevcheck ], !dbg !150
  call void @llvm.dbg.value(metadata i64 %bc.resume.val, metadata !67, metadata !DIExpression()), !dbg !150
  br label %for.body, !dbg !151

for.body:                                         ; preds = %for.body, %scalar.ph
  %indvars.iv = phi i64 [ %bc.resume.val, %scalar.ph ], [ %indvars.iv.next.1, %for.body ], !dbg !152
  call void @llvm.dbg.value(metadata i64 %indvars.iv, metadata !68, metadata !DIExpression()), !dbg !152
  tail call void @llvm.assume(i1 %maskcond), !dbg !153
  %arrayidx = getelementptr inbounds double, double* %0, i64 %indvars.iv, !dbg !154
  call void @llvm.dbg.value(metadata double* %arrayidx, metadata !69, metadata !DIExpression()), !dbg !154
  %32 = load double, double* %arrayidx, align 16, !dbg !155
  call void @llvm.dbg.value(metadata double %32, metadata !70, metadata !DIExpression()), !dbg !155
  %add = fadd double %32, 1.000000e+00, !dbg !156
  call void @llvm.dbg.value(metadata double %add, metadata !71, metadata !DIExpression()), !dbg !156
  tail call void @llvm.assume(i1 %maskcond), !dbg !157
  %mul = fmul double %add, 2.000000e+00, !dbg !158
  call void @llvm.dbg.value(metadata double %mul, metadata !72, metadata !DIExpression()), !dbg !158
  store double %mul, double* %arrayidx, align 16, !dbg !159
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1, !dbg !160
  call void @llvm.dbg.value(metadata i64 %indvars.iv.next, metadata !73, metadata !DIExpression()), !dbg !160
  tail call void @llvm.assume(i1 %maskcond), !dbg !161
  %arrayidx.1 = getelementptr inbounds double, double* %0, i64 %indvars.iv.next, !dbg !162
  call void @llvm.dbg.value(metadata double* %arrayidx.1, metadata !74, metadata !DIExpression()), !dbg !162
  %33 = load double, double* %arrayidx.1, align 8, !dbg !163
  call void @llvm.dbg.value(metadata double %33, metadata !75, metadata !DIExpression()), !dbg !163
  %add.1 = fadd double %33, 1.000000e+00, !dbg !164
  call void @llvm.dbg.value(metadata double %add.1, metadata !76, metadata !DIExpression()), !dbg !164
  tail call void @llvm.assume(i1 %maskcond), !dbg !165
  %mul.1 = fmul double %add.1, 2.000000e+00, !dbg !166
  call void @llvm.dbg.value(metadata double %mul.1, metadata !77, metadata !DIExpression()), !dbg !166
  store double %mul.1, double* %arrayidx.1, align 8, !dbg !167
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.next, 1, !dbg !168
  call void @llvm.dbg.value(metadata i64 %indvars.iv.next.1, metadata !78, metadata !DIExpression()), !dbg !168
  %exitcond.1 = icmp eq i64 %indvars.iv.next, 1599, !dbg !169
  call void @llvm.dbg.value(metadata i1 %exitcond.1, metadata !79, metadata !DIExpression()), !dbg !169
  br i1 %exitcond.1, label %for.end, label %for.body, !dbg !170, !llvm.loop !171

for.end:                                          ; preds = %middle.block, %for.body
  ret void, !dbg !172
}

CheckFunctionDebugify [Module Verifier]: PASS
BISECT: NOT running pass (2) Loop Vectorization on function (test1)
chrisDebugify: F:
define void @test1() !dbg !9 {
  %p = call align 8 i8* @get(), !dbg !18
  call void @llvm.dbg.value(metadata i8* %p, metadata !12, metadata !DIExpression()), !dbg !18
  %ptrint = ptrtoint i8* %p to i64, !dbg !19
  call void @llvm.dbg.value(metadata i64 %ptrint, metadata !14, metadata !DIExpression()), !dbg !19
  %maskedptr = and i64 %ptrint, 7, !dbg !20
  call void @llvm.dbg.value(metadata i64 %maskedptr, metadata !15, metadata !DIExpression()), !dbg !20
  %maskcond = icmp eq i64 %maskedptr, 0, !dbg !21
  call void @llvm.dbg.value(metadata i1 %maskcond, metadata !16, metadata !DIExpression()), !dbg !21
  call void @llvm.assume(i1 %maskcond), !dbg !22
  ret void, !dbg !23
}

CheckFunctionDebugify [Loop Vectorization]: PASS
chrisDebugify: F:
define void @test1() !dbg !9 {
  %p = call align 8 i8* @get(), !dbg !18
  call void @llvm.dbg.value(metadata i8* %p, metadata !12, metadata !DIExpression()), !dbg !18
  %ptrint = ptrtoint i8* %p to i64, !dbg !19
  call void @llvm.dbg.value(metadata i64 %ptrint, metadata !14, metadata !DIExpression()), !dbg !19
  %maskedptr = and i64 %ptrint, 7, !dbg !20
  call void @llvm.dbg.value(metadata i64 %maskedptr, metadata !15, metadata !DIExpression()), !dbg !20
  %maskcond = icmp eq i64 %maskedptr, 0, !dbg !21
  call void @llvm.dbg.value(metadata i1 %maskcond, metadata !16, metadata !DIExpression()), !dbg !21
  call void @llvm.assume(i1 %maskcond), !dbg !22
  ret void, !dbg !23
}

CheckFunctionDebugify [Module Verifier]: PASS
BISECT: NOT running pass (3) Loop Vectorization on function (test3)
chrisDebugify: F:
define void @test3() !dbg !9 {
  %p = alloca i8, align 8, !dbg !18
  call void @llvm.dbg.value(metadata i8* %p, metadata !12, metadata !DIExpression()), !dbg !18
  %ptrint = ptrtoint i8* %p to i64, !dbg !19
  call void @llvm.dbg.value(metadata i64 %ptrint, metadata !14, metadata !DIExpression()), !dbg !19
  %maskedptr = and i64 %ptrint, 7, !dbg !20
  call void @llvm.dbg.value(metadata i64 %maskedptr, metadata !15, metadata !DIExpression()), !dbg !20
  %maskcond = icmp eq i64 %maskedptr, 0, !dbg !21
  call void @llvm.dbg.value(metadata i1 %maskcond, metadata !16, metadata !DIExpression()), !dbg !21
  call void @llvm.assume(i1 %maskcond), !dbg !22
  ret void, !dbg !23
}

CheckFunctionDebugify [Loop Vectorization]: PASS
chrisDebugify: F:
define void @test3() !dbg !9 {
  %p = alloca i8, align 8, !dbg !18
  call void @llvm.dbg.value(metadata i8* %p, metadata !12, metadata !DIExpression()), !dbg !18
  %ptrint = ptrtoint i8* %p to i64, !dbg !19
  call void @llvm.dbg.value(metadata i64 %ptrint, metadata !14, metadata !DIExpression()), !dbg !19
  %maskedptr = and i64 %ptrint, 7, !dbg !20
  call void @llvm.dbg.value(metadata i64 %maskedptr, metadata !15, metadata !DIExpression()), !dbg !20
  %maskcond = icmp eq i64 %maskedptr, 0, !dbg !21
  call void @llvm.dbg.value(metadata i1 %maskcond, metadata !16, metadata !DIExpression()), !dbg !21
  call void @llvm.assume(i1 %maskcond), !dbg !22
  ret void, !dbg !23
}

CheckFunctionDebugify [Module Verifier]: PASS
